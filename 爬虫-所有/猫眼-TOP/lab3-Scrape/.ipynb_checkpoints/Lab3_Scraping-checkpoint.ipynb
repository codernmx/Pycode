{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "#  INT303 Big Data Analytics\n",
    "\n",
    "\n",
    "##  Lab 3 Scraping\n",
    "\n",
    "**XJTLU**<br>\n",
    "**S1 2021**<br>\n",
    "**Instructors:** Jia WANG <br>\n",
    "**Lab Instructor:** Jia WANG <br>\n",
    "**Authors:** Rahul Dave, David Sondak, Will Claybaugh and Pavlos Protopaps\n",
    "\n",
    "\n",
    "# Introduction\n",
    "As a data scientist, I often find myself looking for external data sources that could be relevant for my machine learning projects. The problem is that it is uncommon to find open source data sets that perfectly correspond to what you are looking for, or free APIs that give you access to data. In this case, web scraping can be one solution to get more data.\n",
    "\n",
    "\n",
    "\n",
    "### How can we get to those web pages?\n",
    "In order to answer those questions, we need to understand a little how websites work. Websites are created using HTML (Hypertext Markup Language), along with CSS (Cascading Style Sheets) and JavaScript. HTML elements are separated by tags and they directly introduce content to the web page. Here is what a basic HTML document looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "import bs4 #this is beautiful soup\n",
    "import time\n",
    "import operator\n",
    "import socket\n",
    "#import cPickle\n",
    "import re # regular expressions\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from pandas import Series\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_context(\"talk\")\n",
    "sns.set_style(\"white\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Scraping with Python:\n",
    "=====================\n",
    "\n",
    "* scraping is all about HTML tags\n",
    "* bad news: \n",
    "    - need to learn about tags\n",
    "    - websites can be ugly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "HTML\n",
    "=====\n",
    "\n",
    "* HyperText Markup Language\n",
    "\n",
    "* standard for creating webpages\n",
    "\n",
    "* HTML tags \n",
    "    - have angle brackets\n",
    "    - typically come in pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "This is an example for a minimal webpage defined in HTML tags. The root tag is `<html>` and then you have the `<head>` tag. This part of the page typically includes the title of the page and might also have other meta information like the author or keywords that are important for search engines. The `<body>` tag marks the actual content of the page. You can play around with the `<h2>` tag trying different header levels. They range from 1 to 6. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<!DOCTYPE html>\n",
       "<html>\n",
       "  <head>\n",
       "    <title>This is a title</title>\n",
       "  </head>\n",
       "  <body>\n",
       "    <h2> Test </h2>\n",
       "    <p>Hello world!</p>\n",
       "  </body>\n",
       "</html>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "htmlString = \"\"\"<!DOCTYPE html>\n",
    "<html>\n",
    "  <head>\n",
    "    <title>This is a title</title>\n",
    "  </head>\n",
    "  <body>\n",
    "    <h2> Test </h2>\n",
    "    <p>Hello world!</p>\n",
    "  </body>\n",
    "</html>\"\"\"\n",
    "\n",
    "htmlOutput = HTML(htmlString)\n",
    "htmlOutput"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Useful Tags\n",
    "===========\n",
    "\n",
    "* heading\n",
    "`<h1></h1> ... <h6></h6>`\n",
    "\n",
    "* paragraph\n",
    "`<p></p>` \n",
    "\n",
    "* line break\n",
    "`<br>` \n",
    "\n",
    "* link with attribute\n",
    "\n",
    "`<a href=\"http://www.example.com/\">An example link</a>`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Warm-up: get the content of the main page\n",
    "First let’s use the requests module to get the HTML of the website’s main page.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<!DOCTYPE html>\\n<!--[if lt IE 7]>      <html lang=\"en-us\" class=\"no-js lt-ie9 lt-ie8 lt-ie7\"> <![endif]-->\\n<!--[if IE 7]>         <html lang=\"en-us\" class=\"no-js lt-ie9 lt-ie8\"> <![endif]-->\\n<!--[if IE 8]>         <html lang=\"en-us\" class=\"no-js lt-ie9\"> <![endif]-->\\n<!--[if gt IE 8]><!--> <html lang=\"en-us\" class=\"no-js\"> <!--<![endif]-->\\n    <head>\\n        <title>\\n    All products | Books to Scrape - Sandbox\\n</title>\\n\\n        <meta http-equiv=\"content-type\" content=\"text/html; charset=UTF-8\" />\\n        <meta name=\"created\" content=\"24th Jun 2016 09:29\" />\\n        <meta name=\"description\" content=\"\" />\\n        <meta name=\"viewport\" content=\"width=device-width\" />\\n        <meta name=\"robots\" content=\"NOARCHIVE,NOCACHE\" />\\n\\n        <!-- Le HTML5 shim, for IE6-8 support of HTML elements -->\\n        <!--[if lt IE 9]>\\n        <script src=\"//html5shim.googlecode.com/svn/trunk/html5.js\"></script>\\n        <![endif]-->\\n\\n        \\n            <link rel=\"shortcut icon\" href=\"static/oscar/favicon.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_url = \"http://books.toscrape.com/index.html\"\n",
    "\n",
    "import requests\n",
    "result = requests.get(main_url)\n",
    "\n",
    "result.text[:1000]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is quite messy! Let’s make this more readable:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beautiful Soup\n",
    "\n",
    "\n",
    "* designed to make your life easier\n",
    "* many good functions for parsing html code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<!--[if lt IE 7]>      <html lang=\"en-us\" class=\"no-js lt-ie9 lt-ie8 lt-ie7\"> <![endif]-->\n",
      "<!--[if IE 7]>         <html lang=\"en-us\" class=\"no-js lt-ie9 lt-ie8\"> <![endif]-->\n",
      "<!--[if IE 8]>         <html lang=\"en-us\" class=\"no-js lt-ie9\"> <![endif]-->\n",
      "<!--[if gt IE 8]><!-->\n",
      "<html class=\"no-js\" lang=\"en-us\">\n",
      " <!--<![endif]-->\n",
      " <head>\n",
      "  <title>\n",
      "   All products | Books to Scrape - Sandbox\n",
      "  </title>\n",
      "  <meta content=\"text/html; charset=utf-8\" http-equiv=\"content-type\"/>\n",
      "  <meta content=\"24th Jun 2016 09:29\" name=\"created\"/>\n",
      "  <meta content=\"\" name=\"description\"/>\n",
      "  <meta content=\"width=device-width\" name=\"viewport\"/>\n",
      "  <meta content=\"NOARCHIVE,NOCACHE\" name=\"robots\"/>\n",
      "  <!-- Le HTML5 shim, for IE6-8 support of HTML elements -->\n",
      "  <!--[if lt IE 9]>\n",
      "        <script src=\"//html5shim.googlecode.com/svn/trunk/html5.js\"></script>\n",
      "        <![endif]-->\n",
      "  <link href=\"static/oscar/favicon.ico\" rel=\"shortcut icon\"/>\n",
      "  <link href=\"static/oscar/css/styles.css\" rel=\"stylesheet\" type=\"tex\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(result.text, 'html.parser')\n",
    "\n",
    "print(soup.prettify()[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find book URLs on the main page\n",
    "Now let’s start to dive deeper into the subject. In order to get the book data, we need to be able to access their product page. The first step consist in finding the URL of every book product page.\n",
    "In your browser, go onto the website main page, right-click on the name of a product and click on inspect. This will show you the HTML part of the web page corresponding to this element. Congratulations, you have found the first book link!\n",
    "\n",
    "Note the structure of the HTML code:\n",
    "\n",
    "![avatar](12.png)\n",
    "\n",
    "BeautifulSoup enables us to find those special ‘article’ tags. We can wall the find() function in order to find the first occurence of this tag in the HTML:\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "res=soup.find(\"article\", class_ = \"product_pod\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We still have too much information.\n",
    "Let's dive deeper in the tree by adding the other child tags:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'catalogue/a-light-in-the-attic_1000/index.html'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find(\"article\", class_ = \"product_pod\").div.a.get('href')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now let’s gather all the products URLs on the main web page at once using the findAll() function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_page_products_urls = [x.div.a.get('href') for x in soup.findAll(\"article\", class_ = \"product_pod\")]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function is very handy for finding all the values at once, but you have to check that all the information collected is relevant. Sometimes one same tag can contain completely different data. \n",
    "\n",
    "That is why it is important to be as specific as possible when choosing the tags.\n",
    "\n",
    "Here we decided to rely on the tag ‘article’ with the ‘product_pod’ class because this seems to be a very specific tag and it is unlikely that we can find data other than product data in it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "The following cell just defines a url as a string and then reads the data from that url using the `urllib` library. If you uncomment the print command you see that we got the whole HTML content of the page into the string variable source."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## More detials\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "## filter all external links\n",
    "# create an empty list to collect the valid links\n",
    "external_links = []\n",
    "\n",
    "# write a loop to filter the links\n",
    "# if it starts with 'http' we are happy\n",
    "for l in link_list:\n",
    "    if l[:4] == 'http':\n",
    "        external_links.append(l)\n",
    "\n",
    "# this throws an error! It says something about 'NoneType'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Let's filter those objects out in the for loop\n",
    "external_links = []\n",
    "\n",
    "# write a loop to filter the links\n",
    "# if it is not None and starts with 'http' we are happy\n",
    "for l in link_list:\n",
    "    if l is not None and l[:4] == 'http':\n",
    "        external_links.append(l)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Note: The above `if` condition works because of lazy evaluation in Python. The `and` statement becomes `False` if the first part is `False`, so there is no need to ever evaluate the second part. Thus a `None` entry in the list gets never asked about its first four characters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# and we can put this in a list comprehension as well, it almost reads like \n",
    "# a sentence.\n",
    "\n",
    "res=[l for l in link_list if l is not None and l.startswith('http')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Tips\n",
    "\n",
    "`tmp` now is actually a list of lists containing the hall of fame entries. \n",
    "Here is some advanced Python on how to print really just one entry per list item.\n",
    "\n",
    "The cool things about this are: \n",
    "* The use of `\"\"` to just access the `join` function of strings.\n",
    "* The `join` function itself\n",
    "* that you can actually have two nested for loops in a list comprehension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "## use ul as entry point\n",
    "entry_point = soup.find('ul')\n",
    "\n",
    "## get hall of fame list from entry point\n",
    "## skip the first entry \n",
    "hall_of_fame_list = entry_point.contents[1:]\n",
    "\n",
    "## reformat into a list containing strings\n",
    "tmp = []\n",
    "for li in hall_of_fame_list:\n",
    "    tmp.append(li.contents)\n",
    "tmp    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "test =  [\"\".join(str(a) for a in sublist) for sublist in tmp]\n",
    "print ('\\n'.join(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#  Sum up the above as a function \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAndParseURL(url):\n",
    "    result = requests.get(url)\n",
    "    soup = BeautifulSoup(result.text, 'html.parser')\n",
    "    return(soup)\n",
    "\n",
    "def getBooksURLs(url):\n",
    "    soup = getAndParseURL(url)\n",
    "    # remove the index.html part of the base url before returning the results\n",
    "    return([\"http://books.toscrape.com/\" + x.a.get('href') for x in soup.findAll( \"div\", class_=\"image_container\")])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let’s do it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://books.toscrape.com/index.html\"\n",
    "booksURLs=getBooksURLs(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://books.toscrape.com/catalogue/a-light-in-the-attic_1000/index.html'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "booksURLs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<!--[if lt IE 7]>      <html lang=\"en-us\" class=\"no-js lt-ie9 lt-ie8 lt-ie7\"> <![endif]-->\n",
      "<!--[if IE 7]>         <html lang=\"en-us\" class=\"no-js lt-ie9 lt-ie8\"> <![endif]-->\n",
      "<!--[if IE 8]>         <html lang=\"en-us\" class=\"no-js lt-ie9\"> <![endif]-->\n",
      "<!--[if gt IE 8]><!-->\n",
      "<html class=\"no-js\" lang=\"en-us\">\n",
      " <!--<![endif]-->\n",
      " <head>\n",
      "  <title>\n",
      "   A Light in the Attic | Books to Scrape - Sandbox\n",
      "  </title>\n",
      "  <meta content=\"text/html; charset=utf-8\" http-equiv=\"content-type\"/>\n",
      "  <me\n"
     ]
    }
   ],
   "source": [
    "soup=getAndParseURL(booksURLs[0])\n",
    "print(soup.prettify()[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup=getAndParseURL(booksURLs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"It's hard to imagine a world without A Light in the Attic. This now-classic collection of poetry and drawings from Shel Silverstein celebrates its 20th anniversary with this special edition. Silverstein's humorous and creative verse can amuse the dowdiest of readers. Lemon-faced adults and fidgety kids sit still and read these rhythmic words and laugh and smile and love th It's hard to imagine a world without A Light in the Attic. This now-classic collection of poetry and drawings from Shel Silverstein celebrates its 20th anniversary with this special edition. Silverstein's humorous and creative verse can amuse the dowdiest of readers. Lemon-faced adults and fidgety kids sit still and read these rhythmic words and laugh and smile and love that Silverstein. Need proof of his genius? RockabyeRockabye baby, in the treetopDon't you know a treetopIs no safe place to rock?And who put you up there,And your cradle, too?Baby, I think someone down here'sGot it in for you. Shel, you never sounded so good. ...more\""
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.findAll(\"p\")[-1].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>price</th>\n",
       "      <th>nb_in_stock</th>\n",
       "      <th>url_img</th>\n",
       "      <th>product_category</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A Light in the Attic</td>\n",
       "      <td>51.77</td>\n",
       "      <td>22</td>\n",
       "      <td>http://books.toscrape.com/catalogue/a-light-in...</td>\n",
       "      <td>poetry_23</td>\n",
       "      <td>Three</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tipping the Velvet</td>\n",
       "      <td>53.74</td>\n",
       "      <td>20</td>\n",
       "      <td>http://books.toscrape.com/catalogue/tipping-th...</td>\n",
       "      <td>historical-fiction_4</td>\n",
       "      <td>One</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Soumission</td>\n",
       "      <td>50.10</td>\n",
       "      <td>20</td>\n",
       "      <td>http://books.toscrape.com/catalogue/soumission...</td>\n",
       "      <td>fiction_10</td>\n",
       "      <td>One</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sharp Objects</td>\n",
       "      <td>47.82</td>\n",
       "      <td>20</td>\n",
       "      <td>http://books.toscrape.com/catalogue/sharp-obje...</td>\n",
       "      <td>mystery_3</td>\n",
       "      <td>Four</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sapiens: A Brief History of Humankind</td>\n",
       "      <td>54.23</td>\n",
       "      <td>20</td>\n",
       "      <td>http://books.toscrape.com/catalogue/sapiens-a-...</td>\n",
       "      <td>history_32</td>\n",
       "      <td>Five</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    name  price nb_in_stock  \\\n",
       "0                   A Light in the Attic  51.77          22   \n",
       "1                     Tipping the Velvet  53.74          20   \n",
       "2                             Soumission  50.10          20   \n",
       "3                          Sharp Objects  47.82          20   \n",
       "4  Sapiens: A Brief History of Humankind  54.23          20   \n",
       "\n",
       "                                             url_img      product_category  \\\n",
       "0  http://books.toscrape.com/catalogue/a-light-in...             poetry_23   \n",
       "1  http://books.toscrape.com/catalogue/tipping-th...  historical-fiction_4   \n",
       "2  http://books.toscrape.com/catalogue/soumission...            fiction_10   \n",
       "3  http://books.toscrape.com/catalogue/sharp-obje...             mystery_3   \n",
       "4  http://books.toscrape.com/catalogue/sapiens-a-...            history_32   \n",
       "\n",
       "  rating  \n",
       "0  Three  \n",
       "1    One  \n",
       "2    One  \n",
       "3   Four  \n",
       "4   Five  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = []\n",
    "prices = []\n",
    "nb_in_stock = []\n",
    "img_urls = []\n",
    "categories = []\n",
    "ratings = []\n",
    "\n",
    "# scrape data for every book URL: this may take some time\n",
    "for url in booksURLs:\n",
    "    soup = getAndParseURL(url)\n",
    "    # product name\n",
    "    names.append(soup.find(\"div\", class_ = re.compile(\"product_main\")).h1.text)\n",
    "    # product price\n",
    "    prices.append(soup.find(\"p\", class_ = \"price_color\").text[2:]) # get rid of the pound sign\n",
    "    # number of available products\n",
    "    nb_in_stock.append(re.sub(\"[^0-9]\", \"\", soup.find(\"p\", class_ = \"instock availability\").text)) # get rid of non numerical characters\n",
    "    # image url\n",
    "    img_urls.append(url.replace(\"index.html\", \"\") + soup.find(\"img\").get(\"src\"))\n",
    "    # product category\n",
    "    categories.append(soup.find(\"a\", href = re.compile(\"../category/books/\")).get(\"href\").split(\"/\")[3])\n",
    "    # ratings\n",
    "    ratings.append(soup.find(\"p\", class_ = re.compile(\"star-rating\")).get(\"class\")[1])\n",
    "    \n",
    "# add data into pandas df\n",
    "import pandas as pd\n",
    "\n",
    "scraped_data = pd.DataFrame({'name': names, 'price': prices, 'nb_in_stock': nb_in_stock, \"url_img\": img_urls, \"product_category\": categories, \"rating\": ratings})\n",
    "scraped_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
